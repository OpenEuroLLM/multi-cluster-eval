[project]
name = "oellm"
version = "0.1.0"
description = "OpenEuroLLM CLI"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "pandas",
    "jsonargparse[all]",
    "datasets<4.0.0",
    "rich",
    "torch",
    "lm-eval",
    "huggingface_hub",
    "pyyaml",
    "questionary",
]

[project.scripts]
oellm = "oellm.main:main"

[build-system]
requires = ["uv_build>=0.7.19,<0.8.0"]
build-backend = "uv_build"

[tool.uv.build-backend]
module-name = "oellm"
module-root = ""
include = ["oellm/clusters.yaml", "oellm/task-groups.yaml"]

[tool.uv.sources]
torch = [
    { index = "pytorch-cpu" },
]
torchvision = [
    { index = "pytorch-cpu" },
]

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[tool.ruff]
line-length = 88
target-version = "py38"

[tool.ruff.lint]
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "UP",   # pyupgrade
]
ignore = [
    "E501",  # line too long
    "B008",  # do not perform function calls in argument defaults
    "C901",  # too complex
    "W191",  # indentation contains tabs
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"

[dependency-groups]
dev = [
    "pytest>=8.4.1",
]
